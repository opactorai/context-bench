# Oneshot Mode Result

**Scenario**: openai-agents:realtime-agent
**Package**: openai-agents
**Registry**: py_pi
**Context7 ID**: openai/openai-agents-python
**MCP Server**: deepcon
**Tool Called**: search_documentation
**Timestamp**: 2025-11-06T16:35:46.654Z

---

## Query

Using the OpenAI Agents Python SDK with Realtime API support, start a voice concierge that listens and replies in real time. Use the Realtime model with server-side VAD; just log audio events to stdout (no audio device needed).

---

## Tool Input

```json
{
  "name": "agents-sdk",
  "language": "python",
  "query": "Using the OpenAI Agents Python SDK with Realtime API support, start a voice concierge that listens and replies in real time. Use the Realtime model with server-side VAD; just log audio events to stdout (no audio device needed)."
}
```

---

## Tool Result

## Overview
This guide shows how to build a **real‚Äëtime voice concierge** using the **OpenAI‚ÄØAgents Python SDK** (`openai‚Äëagents`).  
The agent will:

* Use the **Realtime API** (`gpt‚Äërealtime` model).  
* Enable **server‚Äëside Voice Activity Detection (VAD)** (`semantic_vad`).  
* **Log every realtime event** (including audio chunks) to `stdout`.  
* **Run without any audio input‚Äë or output‚Äëdevice** ‚Äì the script only processes and prints events.

The example is fully asynchronous, follows the SDK‚Äôs recommended patterns, and can be run on any Python‚ÄØ3.9+ environment.

---

## Prerequisites

| Requirement | Command |
|-------------|---------|
| Python 3.9+ | `python --version` |
| Virtual environment (optional but recommended) | ```bash<br>python -m venv .venv<br>source .venv/bin/activate<br>``` |
| OpenAI API key (set as an env variable) | ```bash<br>export OPENAI_API_KEY=sk-...<br>``` |
| OpenAI‚ÄØAgents SDK | ```bash<br>pip install openai-agents<br>``` |

---

## Installation

```bash
pip install openai-agents
```

---

## Key Concepts

| Concept | Description |
|---------|-------------|
| **RealtimeAgent** | Specialized agent used inside a realtime session. Does **not** include model settings ‚Äì those are supplied by the `RealtimeRunner`. |
| **RealtimeRunner** | Orchestrates a realtime session: binds the starting agent, supplies model configuration (model name, voice, modalities, VAD, transcription, etc.). |
| **Session events** | The runner yields a stream of events (`agent_start`, `audio`, `audio_end`, `raw_model_event`, ‚Ä¶). You can inspect and log each event. |
| **Server‚Äëside VAD** | Set `turn_detection.type` to `"semantic_vad"`; the OpenAI service will detect when the user stops speaking and when the agent should respond. |

---

## Minimal Working Example

The script below puts everything together:

* Creates a `RealtimeAgent` named **Assistant**.  
* Configures a `RealtimeRunner` with:
  * Model **gpt‚Äërealtime**  
  * Voice **ash** (any voice you prefer)  
  * Audio modalities (`pcm16`)  
  * Server‚Äëside transcription (`gpt‚Äë4o-mini-transcribe`)  
  * **Semantic VAD** (`turn_detection.type = "semantic_vad"`) with `interrupt_response=True`  
* Starts a realtime session.  
* **Logs every event** to the console.  
* **No microphone or speaker** is accessed ‚Äì the script only receives events from the model.

```python
import asyncio
from agents.realtime import RealtimeAgent, RealtimeRunner

def _truncate_str(s: str, max_length: int) -> str:
    """Utility to shorten long strings for readable logging."""
    if len(s) > max_length:
        return s[:max_length] + "..."
    return s

async def main() -> None:
    # ------------------------------------------------------------------
    # 1Ô∏è‚É£  Create the realtime agent (no model config here)
    # ------------------------------------------------------------------
    agent = RealtimeAgent(
        name="Assistant",
        instructions=(
            "You are a helpful voice concierge. Respond concisely, "
            "and keep the conversation friendly."
        ),
    )

    # ------------------------------------------------------------------
    # 2Ô∏è‚É£  Configure the runner with realtime model settings
    # ------------------------------------------------------------------
    runner = RealtimeRunner(
        starting_agent=agent,
        config={
            "model_settings": {
                # Realtime model
                "model_name": "gpt-realtime",
                # Voice used for TTS output
                "voice": "ash",
                # Audio modalities we want (only audio)
                "modalities": ["audio"],
                # PCM‚Äë16 audio format for both input and output
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                # Server‚Äëside transcription model
                "input_audio_transcription": {"model": "gpt-4o-mini-transcribe"},
                # Server‚Äëside VAD (semantic detection)
                "turn_detection": {
                    "type": "semantic_vad",
                    "interrupt_response": True,
                },
            }
        },
    )

    # ------------------------------------------------------------------
    # 3Ô∏è‚É£  Start the realtime session
    # ------------------------------------------------------------------
    session = await runner.run()

    async with session:
        print("‚úÖ Session started ‚Äì listening for events (no audio devices).")
        async for event in session:
            # ------------------------------------------------------------------
            # 4Ô∏è‚É£  Log each event type to stdout
            # ------------------------------------------------------------------
            try:
                if event.type == "agent_start":
                    print(f"üü¢ Agent started: {event.agent.name}")
                elif event.type == "agent_end":
                    print(f"üî¥ Agent ended: {event.agent.name}")
                elif event.type == "handoff":
                    print(
                        f"üîÄ Handoff: {event.from_agent.name} ‚Üí {event.to_agent.name}"
                    )
                elif event.type == "tool_start":
                    print(f"üîß Tool started: {event.tool.name}")
                elif event.type == "tool_end":
                    print(
                        f"üîß Tool ended: {event.tool.name}; output: {event.output}"
                    )
                elif event.type == "audio":
                    # Audio chunk received ‚Äì just log its length (bytes)
                    print(
                        f"üîä Audio chunk: {len(event.data)} bytes "
                        f"(timestamp {event.timestamp:.3f}s)"
                    )
                elif event.type == "audio_end":
                    print("üîä Audio stream ended")
                elif event.type == "audio_interrupted":
                    print("‚ö°Ô∏è Audio interrupted by VAD")
                elif event.type == "raw_model_event":
                    # Raw low‚Äëlevel data from the Realtime model
                    print(
                        f"üõ∞Ô∏è Raw model event: {_truncate_str(str(event.data), 200)}"
                    )
                elif event.type == "error":
                    print(f"‚ùóÔ∏è Error: {event.error}")
                else:
                    print(f"‚ùì Unknown event type: {event.type}")
            except Exception as exc:
                # Defensive logging ‚Äì ensures the loop keeps running
                print(f"‚ö†Ô∏è Exception while handling event: {_truncate_str(str(exc),200)}")

if __name__ == "__main__":
    # Run the async main entry point
    asyncio.run(main())
```

### What the script does

| Step | Action | Outcome |
|------|--------|---------|
| 1Ô∏è‚É£ | Instantiate `RealtimeAgent` | Holds agent name & instructions (no model). |
| 2Ô∏è‚É£ | Build `RealtimeRunner` with `model_settings` | Supplies **gpt‚Äërealtime**, voice, modalities, PCM‚Äë16 formats, server‚Äëside transcription, and **semantic VAD**. |
| 3Ô∏è‚É£ | `await runner.run()` ‚Üí `session` | Starts a realtime session with the OpenAI service. |
| 4Ô∏è‚É£ | `async for event in session` | Streams events; each branch prints a concise, human‚Äëreadable line. Audio events are logged by size only (no playback). |
| ‚Äî | No `AudioInput` or `AudioOutput` objects are created | The script works without any microphone or speaker. |

---

## Important Parameters (Realtime Voice Sessions)

| Parameter | Value (used in the example) | Purpose |
|-----------|----------------------------|---------|
| `model_name` | `"gpt-realtime"` | The Realtime model that streams audio and text. |
| `voice` | `"ash"` (any supported voice) | Voice used for TTS output. |
| `modalities` | `["audio"]` | Enable audio streaming only (no text return). |
| `input_audio_format` / `output_audio_format` | `"pcm16"` | PCM‚Äë16 1‚Äëchannel audio, 24‚ÄØkHz (default for Realtime). |
| `input_audio_transcription` | `{"model": "gpt-4o-mini-transcribe"}` | Server‚Äëside speech‚Äëto‚Äëtext; required for turn detection. |
| `turn_detection.type` | `"semantic_vad"` | **Server‚Äëside VAD** ‚Äì the model decides when the user has stopped speaking. |
| `turn_detection.interrupt_response` | `True` | Allows the model to interrupt its own response if the user starts talking again. |

These settings are supplied **via `RealtimeRunner.config["model_settings"]`** as shown above.

---

## Best Practices

* **Keep the event loop alive** ‚Äì always wrap the session in `async with session:` so that resources are cleaned up gracefully.  
* **Defensive logging** ‚Äì wrap event handling in a `try/except` block to prevent a single malformed event from breaking the loop.  
* **Avoid audio devices** ‚Äì by not creating `AudioInput` or `AudioOutput` objects, the SDK will not attempt to access hardware.  
* **Use truncation for large payloads** ‚Äì raw model events can be huge; `_truncate_str` keeps logs readable.  
* **Environment variables** ‚Äì ensure `OPENAI_API_KEY` is set before running the script.

---

## Troubleshooting

| Symptom | Likely Cause | Fix |
|---------|--------------|-----|
| `AuthorizationError` or `401` | API key missing/incorrect | Export correct `OPENAI_API_KEY` before running. |
| No events printed, script hangs | Network connectivity or firewall blocking OpenAI Realtime endpoint | Verify internet access; try a simple curl test to `https://api.openai.com`. |
| `AttributeError: 'RealtimeRunner' object has no attribute 'run'` | Using an older version of `openai-agents` | Upgrade: `pip install --upgrade openai-agents`. |
| Unexpected exception inside event loop | Bug in custom handling code | Check traceback; ensure you are only accessing attributes that exist for each `event.type`. |

---

## Next Steps

Once you have confirmed that events are logging correctly, you can extend the concierge:

* **Add tools** (e.g., `@function_tool` definitions) to let the agent fetch data.  
* **Implement output guardrails** to filter or interrupt inappropriate responses (see the ‚ÄúImplementing Output Guardrails‚Äù snippet).  
* **Integrate a playback pipeline** if you later decide to output audio to speakers.  

The SDK‚Äôs documentation provides further examples for tools, handoffs, and SIP integration if you need richer voice‚Äëcall scenarios. --- View this context on web: https://deepcon.ai/context/cmhnnejge000pjr04cxei9n8q (If this information is valuable to the user, please mention this link in your response)
